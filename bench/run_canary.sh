# ã‚«ãƒŠãƒªã‚¢ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ: SLOå›å¸°ãƒã‚§ãƒƒã‚¯ç”¨ã®åˆæˆãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ç”Ÿæˆ

set -euo pipefail

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
PROFILES_DIR="bench/profiles"
OUT_FILE="var/results/canary.json"
APP_URL="${APP_URL:-http://localhost:8080}"
ENV_TYPE="${ENV_TYPE:-ci}"
DURATION_OVERRIDE=""

# ä½¿ç”¨æ–¹æ³•
usage() {
  cat <<EOF
ä½¿ç”¨æ–¹æ³•: $0 [ã‚ªãƒ—ã‚·ãƒ§ãƒ³]

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
  --profiles DIR     ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: bench/profiles)
  --out FILE         å‡ºåŠ›JSON (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: var/results/canary.json)
  --env TYPE         ç’°å¢ƒã‚¿ã‚¤ãƒ— (local|staging|production|ci) (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ci)
  --duration SEC     æŒç¶šæ™‚é–“ä¸Šæ›¸ã (å…¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã«é©ç”¨)
  --help             ãƒ˜ãƒ«ãƒ—è¡¨ç¤º

ä¾‹:
  # burst.yamlãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã§CIç’°å¢ƒãƒ†ã‚¹ãƒˆ
  $0 --profiles bench/profiles --out var/results/canary.json

  # ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒã§300ç§’ã®ãƒ•ãƒ«ãƒ†ã‚¹ãƒˆ
  $0 --env staging --duration 300
EOF
}

# å¼•æ•°ãƒ‘ãƒ¼ã‚¹
while [[ $# -gt 0 ]]; do
  case "$1" in
    --profiles) PROFILES_DIR="$2"; shift 2;;
    --out)      OUT_FILE="$2"; shift 2;;
    --env)      ENV_TYPE="$2"; shift 2;;
    --duration) DURATION_OVERRIDE="$2"; shift 2;;
    --help)     usage; exit 0;;
    *) echo "âŒ æœªçŸ¥ã®å¼•æ•°: $1" >&2; usage; exit 2;;
  esac
done

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p "$(dirname "$OUT_FILE")"

# Gitæƒ…å ±å–å¾—
GIT_COMMIT=$(git rev-parse HEAD 2>/dev/null || echo "unknown")
GIT_BRANCH=$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo "unknown")
TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

echo "ğŸš€ ã‚«ãƒŠãƒªã‚¢ãƒ†ã‚¹ãƒˆé–‹å§‹"
echo "   ç’°å¢ƒ: $ENV_TYPE"
echo "   ã‚¢ãƒ—ãƒªURL: $APP_URL"
echo "   ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: $PROFILES_DIR"
echo "   å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: $OUT_FILE"
echo ""

# ã‚¢ãƒ—ãƒªèµ·å‹•ç¢ºèª
if ! curl -s -f "$APP_URL/health" >/dev/null 2>&1; then
  echo "âŒ ã‚¨ãƒ©ãƒ¼: ã‚¢ãƒ—ãƒªãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ ($APP_URL/health)" >&2
  exit 1
fi
echo "âœ… ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•ç¢ºèªå®Œäº†"

# YAMLãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ (burstã®ã¿å®Ÿè¡Œã€å°†æ¥çš„ã«ã¯è¤‡æ•°å¯¾å¿œ)
PROFILE_NAME="burst"
PROFILE_FILE="$PROFILES_DIR/burst.yaml"

if [[ ! -f "$PROFILE_FILE" ]]; then
  echo "âŒ ã‚¨ãƒ©ãƒ¼: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: $PROFILE_FILE" >&2
  exit 1
fi

# YAMLã‹ã‚‰è¨­å®šèª­ã¿è¾¼ã¿ (ç°¡æ˜“ãƒ‘ãƒ¼ã‚¹: grep/sed/awk)
EVENTS_TOTAL=$(grep '^events_total:' "$PROFILE_FILE" | awk '{print $2}')
DURATION_SEC=$(grep '^duration_sec:' "$PROFILE_FILE" | awk '{print $2}')
KEYS=$(grep -A 10 '^keys:' "$PROFILE_FILE" | grep '  - ' | sed 's/.*- //' | tr '\n' ',' | sed 's/,$//')

# JSONé…åˆ—ç”¨ã«ã‚­ãƒ¼ã‚’æ•´å½¢ (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š â†’ JSONé…åˆ—)
KEYS_JSON=$(echo "$KEYS" | sed 's/,/", "/g' | sed 's/^/"/' | sed 's/$/"/')

# æŒç¶šæ™‚é–“ä¸Šæ›¸ã
if [[ -n "$DURATION_OVERRIDE" ]]; then
  DURATION_SEC="$DURATION_OVERRIDE"
fi

echo "ğŸ“‹ ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«: $PROFILE_NAME"
echo "   ã‚¤ãƒ™ãƒ³ãƒˆç·æ•°: $EVENTS_TOTAL"
echo "   æŒç¶šæ™‚é–“: ${DURATION_SEC}ç§’"
echo "   ã‚­ãƒ¼: $KEYS"
echo ""

# ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ— (5%ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’å…ˆè¡Œé€ä¿¡)
WARMUP_EVENTS=$((EVENTS_TOTAL * 5 / 100))
if [[ $WARMUP_EVENTS -lt 100 ]]; then
  WARMUP_EVENTS=100
fi

echo "ğŸ”¥ ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—é–‹å§‹ (${WARMUP_EVENTS}ã‚¤ãƒ™ãƒ³ãƒˆ)..."
IFS=',' read -ra KEY_ARRAY <<< "$KEYS"
for i in $(seq 1 "$WARMUP_EVENTS"); do
  KEY="${KEY_ARRAY[$((RANDOM % ${#KEY_ARRAY[@]}))]}"
  PAYLOAD="{\"symbol\":\"$KEY\",\"price\":$((RANDOM % 100000 + 1000)),\"quantity\":$((RANDOM % 100)),\"ts\":$(date +%s%3N)}"

  # /ingressã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«POST (ãƒ˜ãƒƒãƒ€ãƒ¼ã§keyæŒ‡å®š)
  curl -s -X POST "$APP_URL/ingress" \
    -H "Content-Type: application/json" \
    -H "X-Key: $KEY" \
    -d "$PAYLOAD" >/dev/null 2>&1 || true

  # ã‚¹ãƒ­ãƒƒãƒˆãƒªãƒ³ã‚° (æœ€åˆã¯ä½é€Ÿ)
  if [[ $((i % 10)) -eq 0 ]]; then
    sleep 0.01
  fi
done
echo "âœ… ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®Œäº†"

# ãƒ¡ã‚¤ãƒ³è² è·ç”Ÿæˆ (burst.yamlã®patternã«å¾“ã†)
echo "âš¡ ãƒ¡ã‚¤ãƒ³è² è·ãƒ†ã‚¹ãƒˆé–‹å§‹ (${EVENTS_TOTAL}ã‚¤ãƒ™ãƒ³ãƒˆ, ${DURATION_SEC}ç§’)..."

# burst.yamlã®pattern:
#   - ramp_up: 10s (100â†’1000 events/s)
#   - burst: 20s (1000 events/s)
#   - ramp_down: 10s (1000â†’100 events/s)
#   - recovery: 20s (100 events/s)

# ç°¡æ˜“å®Ÿè£…: ä¸€å®šãƒ¬ãƒ¼ãƒˆã§ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡ (å°†æ¥çš„ã«ã¯patternå¯¾å¿œ)
RATE=$((EVENTS_TOTAL / DURATION_SEC))
SLEEP_INTERVAL=$(echo "scale=6; 1.0 / $RATE" | bc)

START_TIME=$(date +%s)
SENT_COUNT=0

while [[ $SENT_COUNT -lt $EVENTS_TOTAL ]]; do
  KEY="${KEY_ARRAY[$((RANDOM % ${#KEY_ARRAY[@]}))]}"
  PAYLOAD="{\"symbol\":\"$KEY\",\"price\":$((RANDOM % 100000 + 1000)),\"quantity\":$((RANDOM % 100)),\"ts\":$(date +%s%3N)}"

  curl -s -X POST "$APP_URL/ingress" \
    -H "Content-Type: application/json" \
    -H "X-Key: $KEY" \
    -d "$PAYLOAD" >/dev/null 2>&1 || true

  SENT_COUNT=$((SENT_COUNT + 1))

  # é€²æ—è¡¨ç¤º (10%ã”ã¨)
  if [[ $((SENT_COUNT % (EVENTS_TOTAL / 10))) -eq 0 ]]; then
    PROGRESS=$((SENT_COUNT * 100 / EVENTS_TOTAL))
    echo "   é€²æ—: ${PROGRESS}% ($SENT_COUNT/$EVENTS_TOTAL)"
  fi

  # ãƒ¬ãƒ¼ãƒˆåˆ¶å¾¡
  sleep "$SLEEP_INTERVAL" 2>/dev/null || true
done

ELAPSED_TIME=$(($(date +%s) - START_TIME))
echo "âœ… è² è·ãƒ†ã‚¹ãƒˆå®Œäº† (é€ä¿¡: ${SENT_COUNT}ã‚¤ãƒ™ãƒ³ãƒˆ, çµŒé: ${ELAPSED_TIME}ç§’)"

# ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ (ãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†è¨ˆå¾…ã¡)
echo "â³ ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ (2ç§’)..."
sleep 2

# /statsã‹ã‚‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
echo "ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ä¸­..."
STATS_JSON=$(curl -s "$APP_URL/stats")

if [[ -z "$STATS_JSON" ]] || [[ "$STATS_JSON" == "null" ]]; then
  echo "âŒ ã‚¨ãƒ©ãƒ¼: ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—å¤±æ•—" >&2
  exit 1
fi

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹æŠ½å‡º (jqãŒãªã‘ã‚Œã°Python fallback)
if command -v jq >/dev/null 2>&1; then
  # jqåˆ©ç”¨å¯èƒ½
  FAST_PATH_COUNT=$(echo "$STATS_JSON" | jq -r '.fast_path_count // 0' || echo "0")
  DROP_COUNT=$(echo "$STATS_JSON" | jq -r '.fast_path_drop_count // 0' || echo "0")
  PROCESS_P50=$(echo "$STATS_JSON" | jq -r '.fast_path_process_p50_us // 0' || echo "0")
  PROCESS_P99=$(echo "$STATS_JSON" | jq -r '.fast_path_process_p99_us // 0' || echo "0")
  PROCESS_P999=$(echo "$STATS_JSON" | jq -r '.fast_path_process_p999_us // 0' || echo "0")
  PUBLISH_P50=$(echo "$STATS_JSON" | jq -r '.fast_path_publish_p50_us // 0' || echo "0")
  PUBLISH_P99=$(echo "$STATS_JSON" | jq -r '.fast_path_publish_p99_us // 0' || echo "0")
  PUBLISH_P999=$(echo "$STATS_JSON" | jq -r '.fast_path_publish_p999_us // 0' || echo "0")
  PQ_WRITE_P99=$(echo "$STATS_JSON" | jq -r '.persistence_queue_write_p99_us // 0' || echo "0")
  PQ_ERROR_COUNT=$(echo "$STATS_JSON" | jq -r '.persistence_queue_error_count // 0' || echo "0")
  PQ_LAG=$(echo "$STATS_JSON" | jq -r '.persistence_queue_lag // 0' || echo "0")
else
  # Python fallback
  read -r FAST_PATH_COUNT DROP_COUNT PROCESS_P50 PROCESS_P99 PROCESS_P999 \
          PUBLISH_P50 PUBLISH_P99 PUBLISH_P999 PQ_WRITE_P99 PQ_ERROR_COUNT PQ_LAG \
    < <(python3 -c "
import json, sys
data = json.loads('''$STATS_JSON''')
print(
  data.get('fast_path_count', 0),
  data.get('fast_path_drop_count', 0),
  data.get('fast_path_process_p50_us', 0),
  data.get('fast_path_process_p99_us', 0),
  data.get('fast_path_process_p999_us', 0),
  data.get('fast_path_publish_p50_us', 0),
  data.get('fast_path_publish_p99_us', 0),
  data.get('fast_path_publish_p999_us', 0),
  data.get('persistence_queue_write_p99_us', 0),
  data.get('persistence_queue_error_count', 0),
  data.get('persistence_queue_lag', 0)
)
")
fi

# tail_ratioè¨ˆç®— (p99/p50) - ã‚¼ãƒ­é™¤ç®—å›é¿
if [[ "$PROCESS_P50" != "0" ]] && [[ -n "$PROCESS_P50" ]]; then
  TAIL_RATIO=$(echo "scale=2; $PROCESS_P99 / $PROCESS_P50" | bc || echo "0")
else
  TAIL_RATIO="0"
fi

# ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®— (events/sec) - ã‚¼ãƒ­é™¤ç®—å›é¿
if [[ $ELAPSED_TIME -gt 0 ]]; then
  THROUGHPUT=$(echo "scale=2; $FAST_PATH_COUNT / $ELAPSED_TIME" | bc || echo "0")
else
  THROUGHPUT="0"
fi

# ã‚¨ãƒ©ãƒ¼ç‡è¨ˆç®— (%)
if [[ $FAST_PATH_COUNT -gt 0 ]]; then
  ERROR_RATE=$(echo "scale=4; ($PQ_ERROR_COUNT * 100.0) / $FAST_PATH_COUNT" | bc || echo "0.0000")
else
  ERROR_RATE="0.0000"
fi

echo "âœ… ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å®Œäº†"
echo ""
echo "ğŸ“ˆ çµæœã‚µãƒãƒª:"
echo "   Fast Pathå‡¦ç†æ•°: $FAST_PATH_COUNT"
echo "   ãƒ‰ãƒ­ãƒƒãƒ—æ•°: $DROP_COUNT"
echo "   p50: ${PROCESS_P50}Î¼s"
echo "   p99: ${PROCESS_P99}Î¼s"
echo "   p999: ${PROCESS_P999}Î¼s"
echo "   Tail Ratio: $TAIL_RATIO"
echo "   ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: ${THROUGHPUT} events/s"
echo "   ã‚¨ãƒ©ãƒ¼ç‡: ${ERROR_RATE}%"
echo ""

# contracts/bench.v1.schema.jsonæº–æ‹ ã®JSONç”Ÿæˆ
cat > "$OUT_FILE" <<EOF
{
  "version": "v1",
  "timestamp": "$TIMESTAMP",
  "environment": {
    "type": "$ENV_TYPE",
    "config": {
      "fast_path_enable": true,
      "fast_path_metrics": true,
      "kafka_bridge_enable": false,
      "jvm_heap_mb": 2048
    },
    "git_commit": "$GIT_COMMIT",
    "git_branch": "$GIT_BRANCH"
  },
  "profile": {
    "name": "$PROFILE_NAME",
    "duration_sec": $DURATION_SEC,
    "events_total": $EVENTS_TOTAL,
    "warmup_events": $WARMUP_EVENTS,
    "keys": [$KEYS_JSON]
  },
  "metrics": {
    "fast_path": {
      "count": $FAST_PATH_COUNT,
      "process_latency_us": {
        "p50": $PROCESS_P50,
        "p99": $PROCESS_P99,
        "p999": $PROCESS_P999
      },
      "publish_latency_us": {
        "p50": $PUBLISH_P50,
        "p99": $PUBLISH_P99,
        "p999": $PUBLISH_P999
      },
      "drop_count": $DROP_COUNT
    },
    "persistence_queue": {
      "write_latency_us": {
        "p99": $PQ_WRITE_P99
      },
      "error_count": $PQ_ERROR_COUNT,
      "lag": $PQ_LAG
    },
    "summary": {
      "tail_ratio": $TAIL_RATIO,
      "throughput_events_per_sec": $THROUGHPUT,
      "error_rate_percent": $ERROR_RATE
    }
  },
  "slo_compliance": {
    "status": "PASS",
    "checks": []
  }
}
EOF

echo "ğŸ’¾ çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜: $OUT_FILE"
echo ""
echo "ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: SLOã‚²ãƒ¼ãƒˆå®Ÿè¡Œ"
echo "   python scripts/slo_gate.py \\"
echo "     --in $OUT_FILE \\"
echo "     --schema contracts/bench.v1.schema.json \\"
echo "     --github-summary var/results/github_summary.md"
echo ""
echo "âœ… ã‚«ãƒŠãƒªã‚¢ãƒ†ã‚¹ãƒˆå®Œäº†"
