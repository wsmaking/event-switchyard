#!/usr/bin/env python3
"""
æœ€å°å†ç¾ãƒªãƒ—ãƒ¬ã‚¤æŠ½å‡º (Minimal Replay Extractor)

ç›®çš„:
  ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç™ºç”Ÿæ™‚åˆ»ã®å‰å¾Œ15åˆ†é–“ã®Chronicle Queue (WAL) ã‹ã‚‰ã€
  é–¢é€£ã‚¤ãƒ™ãƒ³ãƒˆã®ã¿ã‚’æŠ½å‡ºã—ã€æœ€å°é™ã®å†ç¾å¯èƒ½ãªãƒªãƒ—ãƒ¬ã‚¤ã‚·ãƒŠãƒªã‚ªã‚’ç”Ÿæˆã™ã‚‹ã€‚

æ©Ÿèƒ½:
  1. æ™‚åˆ»ç¯„å›²ã§ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ (incident_time Â± 15åˆ†)
  2. ã‚­ãƒ¼/ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã§ãƒ•ã‚£ãƒ«ã‚¿ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
  3. WALé †åºã§ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ã‚½ãƒ¼ãƒˆ (ä¾å­˜é–¢ä¿‚ä¿æŒ)
  4. NDJSONã§å‡ºåŠ› (replay/case-*.ndjson)
  5. å†ç”Ÿã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆ (scripts/replay.sh)

ä½¿ç”¨ä¾‹:
  # BTCé–¢é€£ã®ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ­ã‚°ã‹ã‚‰15åˆ†é–“ã®æœ€å°ã‚»ãƒƒãƒˆæŠ½å‡º
  python scripts/replay_minset.py \
    --wal var/chronicle \
    --incident-time "2025-11-02T10:30:00Z" \
    --keys BTC \
    --out replay/case-001.ndjson

  # å†ç”Ÿå®Ÿè¡Œ
  bash scripts/replay.sh --in replay/case-001.ndjson --target http://localhost:8080
"""

import json
import sys
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Set
from dataclasses import dataclass
import struct


@dataclass
class Event:
    """ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿"""
    timestamp_ms: int
    key: str
    payload: bytes
    offset: int  # WALå†…ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆ


class ChronicleQueueReader:
    """Chronicle Queue (WAL) èª­ã¿å–ã‚Š"""

    def __init__(self, queue_path: Path):
        self.queue_path = queue_path
        if not queue_path.exists():
            raise FileNotFoundError(f"Chronicle Queue not found: {queue_path}")

    def read_events(self, start_time_ms: int, end_time_ms: int, keys: Optional[Set[str]] = None) -> List[Event]:
        """
        æŒ‡å®šæ™‚åˆ»ç¯„å›²ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’èª­ã¿å–ã‚Š

        æ³¨: Chronicle Queueã®å®Ÿéš›ã®èª­ã¿å–ã‚Šã«ã¯Chronicle Queueãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã€‚
        ã“ã“ã§ã¯ç°¡æ˜“å®Ÿè£…ã¨ã—ã¦ã€NDJSONãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®èª­ã¿å–ã‚Šã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã€‚
        """
        events = []

        # ç°¡æ˜“å®Ÿè£…: var/chronicle/*.ndjson ã‹ã‚‰ã‚¤ãƒ™ãƒ³ãƒˆèª­ã¿å–ã‚Š
        # å®Ÿéš›ã¯Chronicle Queue Wire Formatã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        log_files = sorted(self.queue_path.glob("*.ndjson"))

        for log_file in log_files:
            with open(log_file, 'r') as f:
                for line_num, line in enumerate(f):
                    try:
                        entry = json.loads(line.strip())
                        ts_ms = entry.get("timestamp_ms", 0)
                        key = entry.get("key", "")
                        payload_json = entry.get("payload", {})

                        # æ™‚åˆ»ç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿
                        if not (start_time_ms <= ts_ms <= end_time_ms):
                            continue

                        # ã‚­ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿
                        if keys and key not in keys:
                            continue

                        # Eventã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç”Ÿæˆ
                        events.append(Event(
                            timestamp_ms=ts_ms,
                            key=key,
                            payload=json.dumps(payload_json).encode('utf-8'),
                            offset=line_num
                        ))
                    except json.JSONDecodeError:
                        continue

        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é †ã§ã‚½ãƒ¼ãƒˆ (WALé †åº)
        events.sort(key=lambda e: (e.timestamp_ms, e.offset))

        return events


class ReplayMinsetExtractor:
    """æœ€å°å†ç¾ã‚»ãƒƒãƒˆæŠ½å‡º"""

    def __init__(self, wal_path: Path, incident_time: datetime, window_minutes: int = 15):
        self.wal_path = wal_path
        self.incident_time = incident_time
        self.window_minutes = window_minutes

    def extract(self, keys: Optional[Set[str]] = None) -> List[Event]:
        """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ™‚åˆ» Â± window_minutes ã®ã‚¤ãƒ™ãƒ³ãƒˆæŠ½å‡º"""
        start_time = self.incident_time - timedelta(minutes=self.window_minutes)
        end_time = self.incident_time + timedelta(minutes=self.window_minutes)

        start_time_ms = int(start_time.timestamp() * 1000)
        end_time_ms = int(end_time.timestamp() * 1000)

        reader = ChronicleQueueReader(self.wal_path)
        events = reader.read_events(start_time_ms, end_time_ms, keys)

        return events

    def deduplicate(self, events: List[Event]) -> List[Event]:
        """é‡è¤‡ã‚¤ãƒ™ãƒ³ãƒˆé™¤å» (åŒä¸€key+ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—)"""
        seen = set()
        unique_events = []

        for event in events:
            key_tuple = (event.key, event.timestamp_ms)
            if key_tuple not in seen:
                seen.add(key_tuple)
                unique_events.append(event)

        return unique_events


def write_ndjson(events: List[Event], output_path: Path):
    """NDJSONå½¢å¼ã§å‡ºåŠ›"""
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, 'w') as f:
        for event in events:
            entry = {
                "timestamp_ms": event.timestamp_ms,
                "key": event.key,
                "payload": json.loads(event.payload.decode('utf-8'))
            }
            f.write(json.dumps(entry) + "\n")


def generate_replay_script(ndjson_path: Path, script_path: Path):
    """å†ç”Ÿã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆ (scripts/replay.sh)"""
    script_path.parent.mkdir(parents=True, exist_ok=True)

    script_content = f"""#!/usr/bin/env bash
# ãƒªãƒ—ãƒ¬ã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (è‡ªå‹•ç”Ÿæˆ)
# ä½¿ç”¨æ–¹æ³•: bash {script_path.name} --target http://localhost:8080

set -euo pipefail

TARGET_URL="${{1:-http://localhost:8080}}"
REPLAY_FILE="{ndjson_path}"

echo "ğŸ¬ ãƒªãƒ—ãƒ¬ã‚¤é–‹å§‹: $REPLAY_FILE â†’ $TARGET_URL"
echo ""

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
if ! curl -s -f "$TARGET_URL/health" >/dev/null 2>&1; then
  echo "âŒ ã‚¨ãƒ©ãƒ¼: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¢ãƒ—ãƒªãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“" >&2
  exit 1
fi

# ã‚¤ãƒ™ãƒ³ãƒˆå†ç”Ÿ
EVENT_COUNT=0
START_TIME=$(date +%s)

while IFS= read -r line; do
  KEY=$(echo "$line" | jq -r '.key')
  PAYLOAD=$(echo "$line" | jq -c '.payload')
  TIMESTAMP_MS=$(echo "$line" | jq -r '.timestamp_ms')

  # /ingressã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«POST
  curl -s -X POST "$TARGET_URL/ingress" \\
    -H "Content-Type: application/json" \\
    -H "X-Key: $KEY" \\
    -d "$PAYLOAD" >/dev/null 2>&1 || {{
      echo "âš ï¸  è­¦å‘Š: ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡å¤±æ•— (key=$KEY, ts=$TIMESTAMP_MS)" >&2
    }}

  EVENT_COUNT=$((EVENT_COUNT + 1))

  # é€²æ—è¡¨ç¤º (100ã‚¤ãƒ™ãƒ³ãƒˆã”ã¨)
  if [[ $((EVENT_COUNT % 100)) -eq 0 ]]; then
    echo "   å†ç”Ÿæ¸ˆã¿: ${{EVENT_COUNT}}ã‚¤ãƒ™ãƒ³ãƒˆ"
  fi

  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³: éè² è·é˜²æ­¢)
  # sleep 0.001

done < "$REPLAY_FILE"

ELAPSED_TIME=$(($(date +%s) - START_TIME))
echo ""
echo "âœ… ãƒªãƒ—ãƒ¬ã‚¤å®Œäº†: ${{EVENT_COUNT}}ã‚¤ãƒ™ãƒ³ãƒˆ (çµŒé: ${{ELAPSED_TIME}}ç§’)"
echo "   ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: $((EVENT_COUNT / ELAPSED_TIME)) events/s"
"""

    with open(script_path, 'w') as f:
        f.write(script_content)

    script_path.chmod(0o755)


def main():
    parser = argparse.ArgumentParser(description="æœ€å°å†ç¾ãƒªãƒ—ãƒ¬ã‚¤æŠ½å‡º: ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ™‚åˆ»å‰å¾Œã®ã‚¤ãƒ™ãƒ³ãƒˆæŠ½å‡º")
    parser.add_argument("--wal", required=True, help="Chronicle Queueãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ä¾‹: var/chronicle)")
    parser.add_argument("--incident-time", required=True, help="ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç™ºç”Ÿæ™‚åˆ» (ISO 8601, ä¾‹: 2025-11-02T10:30:00Z)")
    parser.add_argument("--keys", help="å¯¾è±¡ã‚­ãƒ¼ (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š, ä¾‹: BTC,ETH)")
    parser.add_argument("--window-minutes", type=int, default=15, help="æŠ½å‡ºæ™‚é–“çª“ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 15åˆ†)")
    parser.add_argument("--out", required=True, help="å‡ºåŠ›NDJSONãƒ•ã‚¡ã‚¤ãƒ« (ä¾‹: replay/case-001.ndjson)")
    parser.add_argument("--generate-script", action="store_true", help="replay.shç”Ÿæˆ")
    parser.add_argument("--deduplicate", action="store_true", help="é‡è¤‡ã‚¤ãƒ™ãƒ³ãƒˆé™¤å»")

    args = parser.parse_args()

    # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ™‚åˆ»ãƒ‘ãƒ¼ã‚¹
    try:
        incident_time = datetime.fromisoformat(args.incident_time.replace('Z', '+00:00'))
    except ValueError as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ™‚åˆ»ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—: {e}", file=sys.stderr)
        sys.exit(1)

    # ã‚­ãƒ¼ãƒ‘ãƒ¼ã‚¹
    keys = None
    if args.keys:
        keys = set(k.strip() for k in args.keys.split(',') if k.strip())

    print(f"ğŸ“‹ æœ€å°å†ç¾ãƒªãƒ—ãƒ¬ã‚¤æŠ½å‡ºè¨­å®š:")
    print(f"   WALãƒ‘ã‚¹: {args.wal}")
    print(f"   ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ™‚åˆ»: {incident_time.isoformat()}")
    print(f"   æ™‚é–“çª“: Â±{args.window_minutes}åˆ†")
    print(f"   å¯¾è±¡ã‚­ãƒ¼: {', '.join(keys) if keys else 'å…¨ã‚­ãƒ¼'}")
    print(f"   å‡ºåŠ›: {args.out}")
    print()

    # æŠ½å‡ºå®Ÿè¡Œ
    wal_path = Path(args.wal)
    extractor = ReplayMinsetExtractor(wal_path, incident_time, args.window_minutes)

    try:
        events = extractor.extract(keys)
    except FileNotFoundError as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
        sys.exit(1)

    if not events:
        print("âš ï¸  è­¦å‘Š: æŠ½å‡ºã‚¤ãƒ™ãƒ³ãƒˆæ•°ã‚¼ãƒ­ã€‚æ™‚åˆ»ç¯„å›²ã¾ãŸã¯ã‚­ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        sys.exit(0)

    # é‡è¤‡é™¤å» (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
    if args.deduplicate:
        original_count = len(events)
        events = extractor.deduplicate(events)
        print(f"ğŸ” é‡è¤‡é™¤å»: {original_count} â†’ {len(events)}ã‚¤ãƒ™ãƒ³ãƒˆ")

    # NDJSONå‡ºåŠ›
    output_path = Path(args.out)
    write_ndjson(events, output_path)
    print(f"ğŸ’¾ ãƒªãƒ—ãƒ¬ã‚¤ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ: {output_path} ({len(events)}ã‚¤ãƒ™ãƒ³ãƒˆ)")

    # å†ç”Ÿã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
    if args.generate_script:
        script_path = Path("scripts/replay.sh")
        generate_replay_script(output_path, script_path)
        print(f"ğŸ“œ å†ç”Ÿã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆ: {script_path}")
        print()
        print("ğŸ¬ å†ç”Ÿå®Ÿè¡Œ:")
        print(f"   bash {script_path} http://localhost:8080")

    print()
    print("âœ… æŠ½å‡ºå®Œäº†")


if __name__ == "__main__":
    main()
